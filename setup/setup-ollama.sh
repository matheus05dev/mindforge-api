#!/bin/bash

echo "ğŸ¤– MindForge - Setting up Ollama models..."
echo ""

# Espera Ollama estar pronto
echo "â³ Waiting for Ollama to be ready..."
until curl -s http://localhost:11434/api/tags > /dev/null 2>&1; do
  echo "   Ollama not ready yet, waiting 2s..."
  sleep 2
done

echo "âœ… Ollama is ready!"
echo ""

# Modelo de embeddings (OBRIGATÃ“RIO pro RAG)
echo "ğŸ“¥ Pulling embedding model: nomic-embed-text (274MB)..."
docker exec mindforge-ollama ollama pull nomic-embed-text
echo "âœ… Embedding model ready!"
echo ""

# Modelo de chat (ESCOLHA UM)
echo "ğŸ“¥ Which chat model do you want?"
echo "1) llama3.1:8b (4.7GB) - Recommended (best quality)"
echo "2) phi3:mini (2.3GB) - Fast (good for low-end PCs)"
echo "3) mistral:7b (4.1GB) - Alternative (good quality)"
echo "4) Skip chat model (only embeddings)"
echo ""
read -p "Choose (1-4): " choice

case $choice in
  1)
    echo "ğŸ“¥ Pulling llama3.1:8b (this may take 5-10 minutes)..."
    docker exec mindforge-ollama ollama pull llama3.1:8b
    echo "âœ… llama3.1:8b ready!"
    ;;
  2)
    echo "ğŸ“¥ Pulling phi3:mini..."
    docker exec mindforge-ollama ollama pull phi3:mini
    echo "âœ… phi3:mini ready!"
    ;;
  3)
    echo "ğŸ“¥ Pulling mistral:7b..."
    docker exec mindforge-ollama ollama pull mistral:7b
    echo "âœ… mistral:7b ready!"
    ;;
  4)
    echo "â­ï¸  Skipping chat model"
    ;;
  *)
    echo "âŒ Invalid choice. Run script again."
    exit 1
    ;;
esac

echo ""
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "âœ… Ollama setup complete!"
echo ""
echo "ğŸ“‹ Installed models:"
docker exec mindforge-ollama ollama list
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
